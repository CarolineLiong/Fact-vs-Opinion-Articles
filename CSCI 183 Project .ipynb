{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Team 1: Caroline Liongosari, Yueqi Su, Daniel Zhang \n",
    "## Determining Factual and Opinionated News Articles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview and Motivation: \n",
    "Provide an overview of the project goals and motivation for it. Consider that this will be read by people who did not see your project proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: \n",
    "Source, scraping method, cleanup, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project group was able to use a dataset generously given to us by researchers Ishan Sahu and Debapriyo Majumdar from the Indian Statistical Institute Kolkata who did a similar project as ours in 2017. The researchers derived their dataset from the Signal Media One-Million News Articles Dataset. Their cleaned and annotated version of this dataset was provided to us. The dataset consists of 98 news articles and has 3 parts:\n",
    "*  **Article Text Length**: the number of characters present in the news article\n",
    "* **Article Text**: the complete text of the news article\n",
    "* **Unit tags**: the factual, non-factual annotations in the format: \n",
    "    * Character position start : Character position end: Annotation\n",
    "    * example: 502:634:FACTUAL implies that the article text from character position 502 to 634 is factual\n",
    "\n",
    "With this dataset we first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/student/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsedData is a 2-D array with entries: [annotatedString, annotation]\n",
    "parsedData = []\n",
    "path = '/home/student/Documents/Project/annotated-news/*.txt'\n",
    "files = glob.glob(path)\n",
    "\n",
    "for file in files:\n",
    "    f = open(file,'r')\n",
    "    inputString = f.read()\n",
    "    \n",
    "    # inputArray: \n",
    "    # [0-2] holds ArticleTextLength.\n",
    "    # [3-5] holds ArticleText.\n",
    "    # [6-end] holds UnitTags.\n",
    "    inputArray = inputString.split('\\n')\n",
    "    articleText = inputArray[4]\n",
    "    unitTag = []\n",
    "    \n",
    "    # inputArray[6] = \"<UnitTags>\"\n",
    "    # inputArray[7] = start of actual Unit Tags.\n",
    "    i = 7\n",
    "    while i<(len(inputArray)-2):\n",
    "        unitTag.append(inputArray[i])\n",
    "        i+=1\n",
    "    \n",
    "    for indexes in unitTag:\n",
    "        # temp = [Character position start, Character position end, Annotation]\n",
    "        temp = indexes.split(':')\n",
    "        rawText = articleText[int(temp[0]):int(temp[1])-1]\n",
    "        #newRawText = \"u'\"+rawText+\"'\"\n",
    "        \n",
    "        processedText = re.sub('\\\\\\\\u[a-zA-Z0-9]{4}',\"\",rawText)\n",
    "        #processedText = unidecode(newRawText)\n",
    "        #parsedData.append([articleText[int(temp[0]):int(temp[1])-1], temp[2]])\n",
    "        parsedData.append([processedText, temp[2]])\n",
    "    \n",
    "    f.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/student/Documents/Project/dataset.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(parsedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-259aaca17b04>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-259aaca17b04>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    csvWriter = csv.writer(my_csv,delimiter=',')\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/home/student/Documents/Project/dataset.csv\"\n",
    "df = pd.read_table(csv_file, sep = ',', names = ['Sentence','Tag'])\n",
    "tokenData = [] # With stopwords.\n",
    "tokenDataFiltered = [] # Without stopwords.\n",
    "for index, row in df.iterrows():\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokenizedSentence = tokenizer.tokenize(row['Sentence']) \n",
    "    tokenData.append([tokenizedSentence, row['Tag']])\n",
    "    wordsFiltered = [] # Temporary holding array for filtered tokens.\n",
    "    # Filtering stopwords.\n",
    "    for w in tokenizedSentence:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    tokenDataFiltered.append([wordsFiltered, row['Tag']])        \n",
    "\n",
    "\n",
    "\n",
    "with open(\"/home/student/Documents/Project/tokenized.csv\",\"w+\") as my_csv:    \n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(tokenData)\n",
    "\n",
    "with open(\"/home/student/Documents/Project/tokenizedNoStopwords.csv\",\"w+\") as my_csv:    \n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(tokenDataFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tag'] = df.Tag.map({'NON_FACTUAL': 0, \"FACTUAL\": 1})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and Y\n",
    "X= df.Sentence\n",
    "y = df.Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# instantiate the vectorizer\n",
    "v = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then create document-term matrix\n",
    "\n",
    "X_train_data = v.fit_transform(X_train)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = v.transform(X_test)\n",
    "X_test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_tokens =  v.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = v.fit_transform(X_train)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = v.transform(X_test)\n",
    "X_test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_tokens = v.get_feature_names()\n",
    "Xt_count = np.sum(X_train_data.toarray(), axis =0)\n",
    "Xt_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token = pd.DataFrame({'word':Xt_tokens, 'count':Xt_count})\n",
    "df_token.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis\n",
    "What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Naive Bayes model using X_train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# TODO\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "# TODO\n",
    "y_pred_class = naive_bayes.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy of class predictions\n",
    "# compute the accuracy scores\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "# TODO\n",
    "matrix =metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.heatmap(matrix.T, square = True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true labels')\n",
    "plt.ylabel('predicting labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print message text for the false positives\n",
    "# TODO# print message text for the false negatives\n",
    "# TODO\n",
    "print X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print message text for the false negatives\n",
    "# TODO\n",
    "print X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import/instantiate/fit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# TODO\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class predictions and predicted probabilities\n",
    "# TODO\n",
    "y_pred_class = logreg.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "# TODO\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 =metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrix2.T, square = True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true labels')\n",
    "plt.ylabel('predicting labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['Sentence']\n",
    "y = df['Tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the class predictions\n",
    "#y_pred_class['prediction'] = pred\n",
    "#glass.plot.scatter(x = 'al', y = 'household')\n",
    "#plt.plot(glass.al, glass.prediction, color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Analysis: \n",
    "What did you learn about the data? How did you answer the questions? How can you justify your answers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xt_tokens = v.get_feature_names()\n",
    "#Xt_count = np.sum(X_train_data.toarray(), axis =0)\n",
    "#Xt_count\n",
    "\n",
    "#Xt_count = np.sum(X_train_data.toarray(), axis =0)\n",
    "#print Xt_count\n",
    "#print Xt_count.shape\n",
    "#print len(Xt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their counts\n",
    "# such that you will have two columns -- count and token\n",
    "# TODO\n",
    "#df_token = pd.DataFrame({'token':Xt_tokens, 'count':Xt_count})\n",
    "#df_token.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate DataFrames for ham and spam\n",
    "non_fact = df[df.Tag==0]\n",
    "fact = df[df.Tag==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn the vocabulary of ALL messages and save it\n",
    "v.fit(df.Sentence)\n",
    "# put the names of all features (tokens) into a variable\n",
    "all_tokens = v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document-term matrices for ham and spam\n",
    "\n",
    "fact_doc = v.transform(fact['Sentence'])\n",
    "nonfact_doc = v.transform(non_fact['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL ham messages\n",
    "# TODO\n",
    "fact_count = np.sum(fact_doc.toarray(), axis=0)\n",
    "fact_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfact_count = np.sum(nonfact_doc.toarray(), axis=0)\n",
    "nonfact_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens= pd.DataFrame({'token':all_tokens, 'fact': fact_count, 'nonfact': nonfact_count})\n",
    "tokens.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
